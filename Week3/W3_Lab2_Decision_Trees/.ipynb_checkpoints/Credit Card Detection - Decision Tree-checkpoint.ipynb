{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c95ccec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "     ---------------------------------------- 83.6/83.6 kB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from opendatasets) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.28.1)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.14)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (4.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle->opendatasets) (22.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110697 sha256=eb4f5293ab6e624309c7c94ddecd32a782c3fb9aab64a252c9870579d876b19e\n",
      "  Stored in directory: c:\\users\\miuler bm\\appdata\\local\\pip\\cache\\wheels\\b2\\3d\\88\\839f363f3ce6b71785b8a95627cd52cb5359e54aba76a7ab76\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle, opendatasets\n",
      "Successfully installed kaggle-1.5.16 opendatasets-0.1.22\n",
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script kaggle.exe is installed in 'C:\\Users\\Miuler BM\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " miulerblas\n",
      "Your Kaggle Key: ········\n",
      "Downloading creditcardfraud.zip to .\\creditcardfraud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 66.0M/66.0M [00:03<00:00, 19.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We will use Scikit learn and Snap ML\n",
    "\n",
    "# install the opendatasets package\n",
    "!pip install opendatasets\n",
    "\n",
    "import opendatasets as od\n",
    "\n",
    "# download the dataset (this is a Kaggle dataset)\n",
    "# during download you will be required to input your Kaggle username and password\n",
    "od.download(\"https://www.kaggle.com/mlg-ulb/creditcardfraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21dc4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting snapml\n",
      "  Downloading snapml-1.14.1-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from snapml) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from snapml) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from snapml) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->snapml) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->snapml) (1.1.1)\n",
      "Installing collected packages: snapml\n",
      "Successfully installed snapml-1.14.1\n"
     ]
    }
   ],
   "source": [
    "# Snap ML is available on PyPI. To install it simply run the pip command below.\n",
    "!pip install snapml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d2d546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need to use in this lab\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfaea465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 284807 observations in the credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Data Set\n",
    "\n",
    "# read the input data\n",
    "raw_data = pd.read_csv('creditcardfraud/creditcard.csv')\n",
    "print(\"There are \" + str(len(raw_data)) + \" observations in the credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(raw_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "# display the first rows in the dataset\n",
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55228459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2848070 observations in the inflated credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "2   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "3   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "4   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "5   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "6   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "7   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "8   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "9   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "2  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "3  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "4  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "5  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "6  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "7  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "8  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "9  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "2 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "3 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "4 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "5 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "6 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "7 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "8 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "9 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_replicas = 10\n",
    "\n",
    "# inflate the original dataset\n",
    "big_raw_data = pd.DataFrame(np.repeat(raw_data.values, n_replicas, axis=0), columns=raw_data.columns)\n",
    "\n",
    "print(\"There are \" + str(len(big_raw_data)) + \" observations in the inflated credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(big_raw_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "# display first rows in the new dataset\n",
    "big_raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c2a64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum amount value is  0.0\n",
      "Maximum amount value is  25691.16\n",
      "90% of the transactions have an amount less or equal than  203.0\n"
     ]
    }
   ],
   "source": [
    "plt.hist(big_raw_data.Amount.values, 100, histtype='bar', facecolor='g')\n",
    "plt.show()\n",
    "\n",
    "print(\"Minimum amount value is \", np.min(big_raw_data.Amount.values))\n",
    "print(\"Maximum amount value is \", np.max(big_raw_data.Amount.values))\n",
    "print(\"90% of the transactions have an amount less or equal than \", np.percentile(raw_data.Amount.values, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a8f75a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape= (2848070, 29) y.shape= (2848070,)\n"
     ]
    }
   ],
   "source": [
    "# Dataset preprocessing\n",
    "\n",
    "# data preprocessing such as scaling/normalization is typically useful for \n",
    "# linear models to accelerate the training convergence\n",
    "\n",
    "# standardize features by removing the mean and scaling to unit variance\n",
    "big_raw_data.iloc[:, 1:30] = StandardScaler().fit_transform(big_raw_data.iloc[:, 1:30])\n",
    "data_matrix = big_raw_data.values\n",
    "\n",
    "# X: feature matrix (for this analysis, we exclude the Time variable from the dataset)\n",
    "X = data_matrix[:, 1:30] #This excludes the last limit (so it is actually 1 to 29)\n",
    "\n",
    "# y: labels vector\n",
    "y = data_matrix[:, 30]\n",
    "\n",
    "# data normalization\n",
    "X = normalize(X, norm=\"l1\")\n",
    "\n",
    "# print the shape of the features matrix and the labels vector\n",
    "print('X.shape=', X.shape, 'y.shape=', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95ae85ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (1993649, 29) Y_train.shape= (1993649,)\n",
      "X_test.shape= (854421, 29) Y_test.shape= (854421,)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Train/Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)       \n",
    "print('X_train.shape=', X_train.shape, 'Y_train.shape=', y_train.shape)\n",
    "print('X_test.shape=', X_test.shape, 'Y_test.shape=', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa5e503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scikit-Learn] Training time (s):  54.08120\n"
     ]
    }
   ],
   "source": [
    "# Building a Decision Tree Classifier\n",
    "\n",
    "# compute the sample weights to be used as input to the train routine so that \n",
    "# it takes into account the class imbalance present in this dataset\n",
    "w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "# import the Decision Tree Classifier Model from scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.tree as tree\n",
    "\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "sklearn_dt = DecisionTreeClassifier(max_depth=4, random_state=35)\n",
    "\n",
    "# train a Decision Tree Classifier using scikit-learn\n",
    "t0 = time.time()\n",
    "sklearn_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "sklearn_time = time.time()-t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.5f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea06457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x000001E77B846CF0>\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the tree:\n",
    "%matplotlib\n",
    "\n",
    "tree.plot_tree(sklearn_dt)\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4234e",
   "metadata": {},
   "source": [
    "### How balanced sample weights work?\n",
    "\n",
    "In summary, when a class is underrepresented and has higher sample weights, the decision tree algorithm takes this into account when evaluating splits. It will prioritize splits that better capture and separate the underrepresented class because doing so would result in a higher reduction in impurity, leading to a higher information gain. This helps the decision tree adapt to class imbalances and ensures that it gives proper consideration to underrepresented classes during the tree-building process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fd3e4",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier with Snap ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59c422f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Training time (s):  2.81477\n"
     ]
    }
   ],
   "source": [
    "# if not already computed, \n",
    "# compute the sample weights to be used as input to the train routine so that \n",
    "# it takes into account the class imbalance present in this dataset\n",
    "# w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "# import the Decision Tree Classifier Model from Snap ML\n",
    "from snapml import DecisionTreeClassifier\n",
    "\n",
    "# Snap ML offers multi-threaded CPU/GPU training of decision trees, unlike scikit-learn\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, use_gpu=True)\n",
    "\n",
    "# to set the number of CPU threads used at training time, set the n_jobs parameter\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, n_jobs=4)\n",
    "\n",
    "# train a Decision Tree Classifier model using Snap ML\n",
    "t0 = time.time()\n",
    "snapml_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "snapml_time = time.time()-t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.5f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6dd41",
   "metadata": {},
   "source": [
    "# Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a728cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : 18.81x \n",
      "[Scikit-Learn] ROC-AUC score : 0.966\n",
      "[Snap ML] ROC-AUC score : 0.966\n"
     ]
    }
   ],
   "source": [
    "# Snap ML vs Scikit-Learn training speedup\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "# run inference and compute the probabilities of the test samples \n",
    "# to belong to the class of fraudulent transactions\n",
    "sklearn_pred = sklearn_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# evaluate the Compute Area Under the Receiver Operating Characteristic \n",
    "# Curve (ROC-AUC) score from the predictions\n",
    "sklearn_roc_auc = roc_auc_score(y_test, sklearn_pred)\n",
    "print('[Scikit-Learn] ROC-AUC score : {0:.3f}'.format(sklearn_roc_auc))\n",
    "\n",
    "# run inference and compute the probabilities of the test samples\n",
    "# to belong to the class of fraudulent transactions\n",
    "snapml_pred = snapml_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# evaluate the Compute Area Under the Receiver Operating Characteristic\n",
    "# Curve (ROC-AUC) score from the prediction scores\n",
    "snapml_roc_auc = roc_auc_score(y_test, snapml_pred)   \n",
    "print('[Snap ML] ROC-AUC score : {0:.3f}'.format(snapml_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515f91e",
   "metadata": {},
   "source": [
    "## Building a SVM with Sci-kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ce5f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scikit-Learn] Training time (s):  74.47\n"
     ]
    }
   ],
   "source": [
    "# import the linear Support Vector Machine (SVM) model from Scikit-Learn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# instatiate a scikit-learn SVM model\n",
    "# to indicate the class imbalance at fit time, set class_weight='balanced'\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "sklearn_svm = LinearSVC(class_weight='balanced', random_state=31, loss=\"hinge\", fit_intercept=False)\n",
    "\n",
    "# train a linear Support Vector Machine model using Scikit-Learn\n",
    "t0 = time.time()\n",
    "sklearn_svm.fit(X_train, y_train)\n",
    "sklearn_time = time.time() - t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.2f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fef5c9",
   "metadata": {},
   "source": [
    "## Building a SVM with Snap ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5449b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Training time (s):  8.43\n"
     ]
    }
   ],
   "source": [
    "# import the Support Vector Machine model (SVM) from Snap ML\n",
    "from snapml import SupportVectorMachine\n",
    "\n",
    "# in contrast to scikit-learn's LinearSVC, Snap ML offers multi-threaded CPU/GPU training of SVMs\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, use_gpu=True, fit_intercept=False)\n",
    "\n",
    "# to set the number of threads used at training time, one needs to set the n_jobs parameter\n",
    "snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, n_jobs=4, fit_intercept=False)\n",
    "# print(snapml_svm.get_params())\n",
    "\n",
    "# train an SVM model using Snap ML\n",
    "t0 = time.time()\n",
    "model = snapml_svm.fit(X_train, y_train)\n",
    "snapml_time = time.time() - t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.2f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac07010",
   "metadata": {},
   "source": [
    "# Evaluate the Scikit Learn and Snap ML SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "625af626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : 8.83x \n",
      "[Scikit-Learn] ROC-AUC score:   0.984\n",
      "[Snap ML] ROC-AUC score:   0.985\n"
     ]
    }
   ],
   "source": [
    "# compute the Snap ML vs Scikit-Learn training speedup\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "# run inference using the Scikit-Learn model\n",
    "# get the confidence scores for the test samples\n",
    "sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "\n",
    "# evaluate accuracy on test set\n",
    "acc_sklearn  = roc_auc_score(y_test, sklearn_pred)\n",
    "print(\"[Scikit-Learn] ROC-AUC score:   {0:.3f}\".format(acc_sklearn))\n",
    "\n",
    "# run inference using the Snap ML model\n",
    "# get the confidence scores for the test samples\n",
    "snapml_pred = snapml_svm.decision_function(X_test)\n",
    "\n",
    "# evaluate accuracy on test set\n",
    "acc_snapml  = roc_auc_score(y_test, snapml_pred)\n",
    "print(\"[Snap ML] ROC-AUC score:   {0:.3f}\".format(acc_snapml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4cf3eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Hinge loss:   0.228\n",
      "[Scikit-Learn] Hinge loss:   0.228\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the loss\n",
    "\n",
    "# get the confidence scores for the test samples\n",
    "sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "snapml_pred  = snapml_svm.decision_function(X_test)\n",
    "\n",
    "# import the hinge_loss metric from scikit-learn\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "# evaluate the hinge loss from the predictions\n",
    "loss_snapml = hinge_loss(y_test, snapml_pred)\n",
    "print(\"[Snap ML] Hinge loss:   {0:.3f}\".format(loss_snapml))\n",
    "\n",
    "# evaluate the hinge loss metric from the predictions\n",
    "loss_sklearn = hinge_loss(y_test, sklearn_pred)\n",
    "print(\"[Scikit-Learn] Hinge loss:   {0:.3f}\".format(loss_snapml))\n",
    "\n",
    "# the two models should give the same Hinge loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
